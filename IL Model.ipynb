{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,Input,BatchNormalization,MaxPooling1D,concatenate\n",
    "from keras.utils import np_utils,multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as bek\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data cell\n",
    "\"\"\"\n",
    "df1=pd.read_csv('/home/dp/Desktop/end/pair_end_merge_BG_random_HR-test-v5-test.csv',index_col=0)\n",
    "\n",
    "\n",
    "cond2 = df1['count']!=0\n",
    "df1 = df1[cond2]\n",
    "\n",
    "#normalize\n",
    "target = 'BG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(ref_values, pred_values):\n",
    "\n",
    "    #Checking to see if the lengths of the reference and prediction arrays are the same\n",
    "    assert (len(ref_values) == len(pred_values)), \"Unequal number of values (reference : {}) (prediction : {}).\".format(len(ref_values), len(pred_values))\n",
    "\n",
    "    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning\n",
    "    if max(ref_values) > 400 or max(pred_values) > 400:\n",
    "        print(\"Input Warning: the maximum reference value {} or the maximum prediction value {} exceeds the normal physiological range of glucose (<400 mg/dl).\".format(max(ref_values), max(pred_values)))\n",
    "    if min(ref_values) < 0 or min(pred_values) < 0:\n",
    "        print(\"Input Warning: the minimum reference value {} or the minimum prediction value {} is less than 0 mg/dl.\".format(min(ref_values),  min(pred_values)))\n",
    "\n",
    "    #Statistics from the data\n",
    "    zone = [0] * 5\n",
    "    for i in range(len(ref_values)):\n",
    "        if (ref_values[i] <= 70 and pred_values[i] <= 70) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):\n",
    "            zone[0] += 1    #Zone A\n",
    "\n",
    "        elif (ref_values[i] >= 180 and pred_values[i] <= 70) or (ref_values[i] <= 70 and pred_values[i] >= 180):\n",
    "            zone[4] += 1    #Zone E\n",
    "\n",
    "        elif ((ref_values[i] >= 70 and ref_values[i] <= 290) and pred_values[i] >= ref_values[i] + 110) or ((ref_values[i] >= 130 and ref_values[i] <= 180) and (pred_values[i] <= (7/5)*ref_values[i] - 182)):\n",
    "            zone[2] += 1    #Zone C\n",
    "        elif (ref_values[i] >= 240 and (pred_values[i] >= 70 and pred_values[i] <= 180)) or (ref_values[i] <= 175/3 and pred_values[i] <= 180 and pred_values[i] >= 70) or ((ref_values[i] >= 175/3 and ref_values[i] <= 70) and pred_values[i] >= (6/5)*ref_values[i]):\n",
    "            zone[3] += 1    #Zone D\n",
    "        else:\n",
    "            zone[1] += 1    #Zone B\n",
    "            \n",
    "    confidence_score = round((zone[0]*5+zone[1]*2.5)/(len(ref_values)*5)*100,2)\n",
    "    \n",
    "    return confidence_score,zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c1(ref_values, pred_values):\n",
    "    \n",
    "    sum_a = 0\n",
    "    for i in range(len(ref_values)):\n",
    "        d = abs(pred_values[i]-ref_values[i])\n",
    "        if((d/ref_values[i])<1):\n",
    "            a = abs(d/ref_values[i]-1)\n",
    "        else:\n",
    "            a = 0\n",
    "        sum_a = sum_a + a\n",
    "    acc = sum_a/len(ref_values)\n",
    "    acc = round(acc*100,2)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model cell\n",
    "'''\n",
    "def base_model():\n",
    "    in_s = Input((406, 1))\n",
    "    model_s = Convolution1D(nb_filter=256, filter_length=3) (in_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=256, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=512, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=1024, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=2048, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Flatten()(model_s)\n",
    "    \n",
    "    \n",
    "    m = BatchNormalization(axis=-1)(model_s)\n",
    "    m = Dense(4096,activation='relu')(m)\n",
    "    m = Dense(2048,activation='relu')(m)\n",
    "    out = Dense(1,activation='linear')(m)\n",
    "    \n",
    "    model = Model(inputs=[in_s], outputs=[out])\n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999)\n",
    "    model = multi_gpu_model(model,gpus=6)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(train_temp,test_temp):\n",
    "    X_train_s = train_temp.iloc[:,7:413]\n",
    "    X_test_s = test_temp.iloc[:,7:413]\n",
    "    \n",
    "    f1=['BG']\n",
    "    Y_train = train_temp[f1]\n",
    "    Y_train = scalert.transform(Y_train)\n",
    "    \n",
    "\n",
    "    X_train_r_s = np.zeros((len(X_train_s), 406, 1))\n",
    "    X_train_r_s[:, :, 0] = X_train_s\n",
    "\n",
    "\n",
    "    X_test_r_s = np.zeros((len(X_test_s), 406, 1))\n",
    "    X_test_r_s[:, :, 0] = X_test_s\n",
    "    \n",
    "\n",
    "    model= base_model()\n",
    "    model.fit([X_train_r_s], Y_train, epochs=1000, batch_size=3000,verbose=0)\n",
    "\n",
    "    \n",
    "    test_pred = model.predict([X_test_r_s])\n",
    "    test_pred1 = scalert.inverse_transform(test_pred)\n",
    "    test_temp['BG_p']=test_pred1\n",
    "    temp_a=0\n",
    "    temp_b=0\n",
    "    test_BG_r=[]\n",
    "    test_BG_p=[]\n",
    "                        \n",
    "    for i,item in enumerate(test_temp['Person No']):\n",
    "        if((test_temp['Person No'].iloc[i]!=temp_a) | (test_temp['time'].iloc[i]!=temp_b)):\n",
    "            \n",
    "            #administrator mode\n",
    "            test_BG_r.append(test_temp['BG'].iloc[i])\n",
    "            temp = test_temp[(test_temp['Person No']==test_temp['Person No'].iloc[i])&(test_temp['time']==test_temp['time'].iloc[i])]\n",
    "            t = np.median(temp['BG_p'])\n",
    "            test_BG_p.append(t)\n",
    "            temp_a = test_temp['Person No'].iloc[i]\n",
    "            temp_b = test_temp['time'].iloc[i]\n",
    "            \n",
    "    print(test_BG_p)\n",
    "    print(test_BG_r)\n",
    "    del model\n",
    "    bek.clear_session()\n",
    "    gc.collect()\n",
    "    return (test_BG_p,test_BG_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "testingNo_all = [1]\n",
    "################\n",
    "\n",
    "for testingNo in testingNo_all:\n",
    "    test_p=[]\n",
    "    test_r=[]\n",
    "    test_zone=[]\n",
    "    acc=[]\n",
    "    for test_time in range(4,16):\n",
    "        test  = df1[(df1['count']==testingNo)&(df1['count_time']==test_time)]\n",
    "        if(test.empty):\n",
    "            continue\n",
    "        else:\n",
    "            test_index = test.index\n",
    "            data_base = df1.drop(test_index)\n",
    "            t = data_base[target]\n",
    "            t = t.values.reshape(-1, 1)\n",
    "            scalert = preprocessing.MinMaxScaler().fit(t)\n",
    "            test_train = data_base[(data_base['count']==testingNo)&(data_base['count_time']<test_time)]\n",
    "    \n",
    "        \n",
    "            p_1=[]\n",
    "            p_2=[]\n",
    "            for i in range(0,3):\n",
    "                (temp_pred,temp_real) = test_step(test_train,test)\n",
    "                p_1.append(temp_pred[0])\n",
    "                p_2.append(temp_pred[1])\n",
    "        \n",
    "        \n",
    "            m_pred=[np.median(p_1),np.median(p_2)]\n",
    "        \n",
    "            test_p.append(m_pred)\n",
    "            test_r.append(temp_real)\n",
    "        \n",
    "            reshape_p=[]\n",
    "            reshape_r=[]\n",
    "\n",
    "            for i in range(len(m_pred)):\n",
    "                reshape_p.append(m_pred[i])\n",
    "            for i in range(len(temp_real)):\n",
    "                reshape_r.append(temp_real[i])\n",
    "                \n",
    "            no_mind,test_z = c(reshape_r,reshape_p)\n",
    "            test_acc = c1(reshape_r,reshape_p)\n",
    "        \n",
    "            acc.append(test_acc)\n",
    "            test_zone.append(test_z)\n",
    "        \n",
    "            print(\"test No:\",testingNo,\"test time:\",test_time)\n",
    "            print(\"BG real:\",temp_real,\" BG pred:\",m_pred,\"accuracy:\",test_acc,\"%\",'test_zone:',test_z)\n",
    "\n",
    "            \n",
    "    d = {'BG_real': test_r, 'BG_pred': test_p, 'test_zone':test_zone,'accuracy':acc}\n",
    "    df_f = pd.DataFrame(data = d)\n",
    "    \n",
    "    ind =[]\n",
    "    for j in range(4,len(df_f.index)+4):\n",
    "        ind.append(j)    \n",
    "    df_f.index=ind\n",
    "    \n",
    "    name_temp =str(testingNo)+'-1000-256.csv'\n",
    "    \n",
    "    df_f.to_csv(name_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
