{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_index =pd.read_csv(\"file_path_index.csv\")\n",
    "merge_all=pd.read_csv('merge_all.csv')\n",
    "\n",
    "d_index = merge_all[merge_all['BG'].isnull()].index\n",
    "merge_all=merge_all.drop(d_index)\n",
    "\n",
    "x = list(np.arange(0, 400, 1))\n",
    "features=['person_time_idx','Person No','time','Time','count_time','count','BG','Area','FW_25','FW_50','FW_75','FW_100','HR']\n",
    "x=features+x\n",
    "output_df=pd.DataFrame(columns=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vally(minmax_df):\n",
    "    vallys_tStamp=minmax_df.loc[minmax_df['M/m']=='lmin']['t(sec)']\n",
    "    return vallys_tStamp\n",
    "def get_pulse_sig(vallys_tStamp):\n",
    "    global output_df\n",
    "    signal_df=pd.read_csv(file_path_index.loc[file_path_index['person_time_idx']=='001_0903']['R4signal'].values[0],delim_whitespace=True,skiprows=6)\n",
    "    return signal_df['AC']\n",
    "\n",
    "def get_profile(pid_t_idx,pid):\n",
    "    profile=list(merge_all.loc[merge_all['person_time_idx']==pid_t_idx,['Time','count_time','count','BG']].values[0])\n",
    "    return profile\n",
    "\n",
    "def FWnM(pulse, peak_amp, peak_i, n=[0.5]):\n",
    "    #FWnM = []\n",
    "    total_len = len(pulse)\n",
    "    for ni in n:\n",
    "        thrd = ni*peak_amp + pulse[0]\n",
    "        left_i = peak_i-len(pulse[:peak_i][pulse[:peak_i]<=thrd])\n",
    "        right_i = len(pulse[peak_i:][pulse[peak_i:]>=thrd])\n",
    "        FWnM = round((right_i+left_i)*4,2) # 4ms\n",
    "        #FWnM.append((right_i+left_i)*100/total_len) # %\n",
    "    \n",
    "    return FWnM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main flow func\n",
    "total_sample=merge_all['person_time_idx'].shape[0]\n",
    "z=0\n",
    "time=0\n",
    "tt=0\n",
    "output_lst=[]\n",
    "for pid_t_idx in merge_all['person_time_idx']:\n",
    "    z=z+1\n",
    "    if z%537==0:\n",
    "        print(z/537*10, \" % done\")\n",
    "    \n",
    "    try:\n",
    "        pid=int(pid_t_idx.split('_')[0])\n",
    "        if(pid!=tt):\n",
    "            time=1\n",
    "            profile_lst = [pid_t_idx,pid,time]+get_profile(pid_t_idx,pid)\n",
    "            tt=pid\n",
    "        else:\n",
    "            time=time+1\n",
    "            profile_lst = [pid_t_idx,pid,time]+get_profile(pid_t_idx,pid)\n",
    "        #profile_lst = [pid_t_idx,pid]+get_profile(pid_t_idx,pid)\n",
    "        #print(pid_t_idx)\n",
    "\n",
    "        #import file\n",
    "        minmax_df=pd.read_csv(file_path_index.loc[file_path_index['person_time_idx']==pid_t_idx]['R4minmax'].values[0],delim_whitespace=True)\n",
    "        signal_df=pd.read_csv(file_path_index.loc[file_path_index['person_time_idx']==pid_t_idx]['R4signal'].values[0],delim_whitespace=True,skiprows=6)\n",
    "\n",
    "    \n",
    "        # get vally_t, vally_idx , HR\n",
    "        vallys_tStamp=minmax_df.loc[(minmax_df['M/m']=='lmin')&(minmax_df['Sig']=='IR')]['t(sec)']\n",
    "        HR=[60/(float(vallys_tStamp[(i+1)])-float(vallys_tStamp[i])) for i in range(len(vallys_tStamp)-1)]\n",
    "        vallys_tStamp=vallys_tStamp.drop(vallys_tStamp.index[0])\n",
    "        \n",
    "        vallys_min_index=minmax_df.loc[(minmax_df['M/m']=='lmin')&(minmax_df['Sig']=='IR')]['index'].apply(int)\n",
    "        vallys_min_index=vallys_min_index.drop(vallys_min_index.index[0])\n",
    "        \n",
    "        vallys_max1_index=minmax_df.loc[(minmax_df['M/m']=='lmax')&(minmax_df['Sig']=='IR')]['index'].apply(int)\n",
    "        vallys_max1_index=vallys_max1_index.drop(vallys_max1_index.index[0])\n",
    "        \n",
    "        vallys_max2_index=minmax_df.loc[(minmax_df['M/m']=='lmx2')&(minmax_df['Sig']=='IR')]['index'].apply(int)\n",
    "        vallys_max2_index=vallys_max2_index.drop(vallys_max2_index.index[0])\n",
    "        \n",
    "        IR_max = [] \n",
    "        for i1,i2 in zip(vallys_max1_index.values, vallys_max2_index.values):\n",
    "            if signal_df['AC'].loc[i1]>signal_df['AC'].loc[i2]:\n",
    "                IR_max.append(i1)\n",
    "            else:\n",
    "                IR_max.append(i2)\n",
    "        start_idx = vallys_min_index.iloc[:-1].values\n",
    "        end_idx = vallys_min_index.iloc[1:].values\n",
    "        peak_idx = IR_max[:-1]\n",
    "        \n",
    "        \n",
    "        if (len(vallys_tStamp)!=len(HR)):\n",
    "            print(len(vallys_tStamp),len(vallys_index),HR)\n",
    "    except:\n",
    "        print('Error on : ',pid_t_idx)\n",
    "    \n",
    "    count=1\n",
    "    \n",
    "    #for index,hr in zip(vallys_min_index,HR):\n",
    "    \n",
    "    for (si,ei,pi,hr) in zip(start_idx, end_idx, peak_idx,HR):\n",
    "        if ((int(si)< 400)|(int(si)+1 > len(signal_df))):\n",
    "            continue\n",
    "        temp_lst= profile_lst.copy()\n",
    "        #print(\"profile_lst len :\",len(profile_lst),\"content :\",profile_lst)\n",
    "        \n",
    "        p_ref_idx = pi-si\n",
    "        rise_area, fall_area = 0, 0\n",
    "        y0 = signal_df['AC'].loc[si]\n",
    "        amp = signal_df['AC'].loc[pi]-y0\n",
    "                \n",
    "        half_level = amp/2 + y0\n",
    "        hli, hri = 0, 0\n",
    "        # inside pulse loop\n",
    "        pulse_seg = signal_df.loc[si+1:ei]['AC']\n",
    "        for i,val in enumerate(pulse_seg,1):\n",
    "            if i<p_ref_idx:\n",
    "                rise_area += (val-y0)\n",
    "                #if val<=half_level:\n",
    "                #    hli = i\n",
    "            else:\n",
    "                fall_area += (val-y0)\n",
    "                #if val>=half_level:\n",
    "                #    hri = i\n",
    "        #portion = [0.25, 0.5, 0.75]\n",
    "        \n",
    "        temp_lst.append((rise_area+fall_area))\n",
    "        \n",
    "        fwhm_dic_25 = FWnM(pulse_seg.values, amp, p_ref_idx, n=[0.25])\n",
    "        temp_lst.append(fwhm_dic_25)\n",
    "        fwhm_dic_50 = FWnM(pulse_seg.values, amp, p_ref_idx, n=[0.5])\n",
    "        temp_lst.append(fwhm_dic_50)\n",
    "        fwhm_dic_75 = FWnM(pulse_seg.values, amp, p_ref_idx, n=[0.75])\n",
    "        temp_lst.append(fwhm_dic_75)\n",
    "        fwhm_dic_100 = (ei-si)*4\n",
    "        temp_lst.append(fwhm_dic_100)\n",
    "        \n",
    "        temp_lst.append(hr)\n",
    "        \n",
    "        #add 200pulse point to data_entry\n",
    "        temp_lst=temp_lst+list(signal_df.iloc[(int(si)-399):(int(si)+1)]['AC'])\n",
    "        \n",
    "        output_lst.append(temp_lst)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df=pd.DataFrame(output_lst,columns=x)\n",
    "print(output_df.shape)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_last=[]\n",
    "HR_last=[]\n",
    "Area_last=[]\n",
    "FW_25_last=[]\n",
    "FW_50_last=[]\n",
    "FW_75_last=[]\n",
    "FW_100_last=[]\n",
    "ppg_last=[]\n",
    "\n",
    "\n",
    "for i,item in enumerate(output_df['Person No']):\n",
    "    p=output_df['count'].iloc[i]\n",
    "    if(p==0):\n",
    "        index = np.random.choice(output_df.index)\n",
    "        ppg_last.append(output_df.iloc[index][13:413].values)\n",
    "        BG_last.append(output_df.iloc[index]['BG'])\n",
    "        HR_last.append(output_df.iloc[index]['HR'])\n",
    "        Area_last.append(output_df.iloc[index]['Area'])\n",
    "        FW_25_last.append(output_df.iloc[index]['FW_25'])\n",
    "        FW_50_last.append(output_df.iloc[index]['FW_50'])\n",
    "        FW_75_last.append(output_df.iloc[index]['FW_75'])\n",
    "        FW_100_last.append(output_df.iloc[index]['FW_100'])\n",
    "    else:\n",
    "        if(output_df['count_time'].iloc[i]==2):\n",
    "            tmp=output_df[(output_df['Person No']==p)]\n",
    "            if(tmp.empty):\n",
    "                index = np.random.choice(output_df.index)\n",
    "                ppg_last.append(output_df.iloc[index][13:413].values)\n",
    "                BG_last.append(output_df.iloc[index]['BG'])\n",
    "                HR_last.append(output_df.iloc[index]['HR'])\n",
    "                Area_last.append(output_df.iloc[index]['Area'])\n",
    "                FW_25_last.append(output_df.iloc[index]['FW_25'])\n",
    "                FW_50_last.append(output_df.iloc[index]['FW_50'])\n",
    "                FW_75_last.append(output_df.iloc[index]['FW_75'])\n",
    "                FW_100_last.append(output_df.iloc[index]['FW_100'])\n",
    "            else:\n",
    "                index = np.random.choice(tmp.index)\n",
    "                ppg_last.append(output_df.iloc[index][13:413].values)\n",
    "                BG_last.append(output_df.iloc[index]['BG'])\n",
    "                HR_last.append(output_df.iloc[index]['HR'])\n",
    "                Area_last.append(output_df.iloc[index]['Area'])\n",
    "                FW_25_last.append(output_df.iloc[index]['FW_25'])\n",
    "                FW_50_last.append(output_df.iloc[index]['FW_50'])\n",
    "                FW_75_last.append(output_df.iloc[index]['FW_75'])\n",
    "                FW_100_last.append(output_df.iloc[index]['FW_100'])\n",
    "        else:\n",
    "            tmp=output_df[(output_df['count']==p)&(output_df['count_time']==output_df['count_time'].iloc[i]-1)]\n",
    "            if(tmp.empty):\n",
    "                index = np.random.choice(output_df.index)\n",
    "                ppg_last.append(output_df.iloc[index][13:413].values)\n",
    "                BG_last.append(output_df.iloc[index]['BG'])\n",
    "                HR_last.append(output_df.iloc[index]['HR'])\n",
    "                Area_last.append(output_df.iloc[index]['Area'])\n",
    "                FW_25_last.append(output_df.iloc[index]['FW_25'])\n",
    "                FW_50_last.append(output_df.iloc[index]['FW_50'])\n",
    "                FW_75_last.append(output_df.iloc[index]['FW_75'])\n",
    "                FW_100_last.append(output_df.iloc[index]['FW_100'])\n",
    "            else:\n",
    "                index = np.random.choice(tmp.index)\n",
    "                ppg_last.append(output_df.iloc[index][13:413].values)\n",
    "                BG_last.append(output_df.iloc[index]['BG'])\n",
    "                HR_last.append(output_df.iloc[index]['HR'])\n",
    "                Area_last.append(output_df.iloc[index]['Area'])\n",
    "                FW_25_last.append(output_df.iloc[index]['FW_25'])\n",
    "                FW_50_last.append(output_df.iloc[index]['FW_50'])\n",
    "                FW_75_last.append(output_df.iloc[index]['FW_75'])\n",
    "                FW_100_last.append(output_df.iloc[index]['FW_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array(ppg_last)\n",
    "arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(np.arange(400)+400)\n",
    "list2 = []\n",
    "for item in list1:\n",
    "    list2.append(str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns=list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['BG_last']=BG_last\n",
    "output_df['Area_last']=Area_last\n",
    "output_df['FW_25_last']=FW_25_last\n",
    "output_df['FW_50_last']=FW_50_last\n",
    "output_df['FW_75_last']=FW_75_last\n",
    "output_df['FW_100_last']=FW_100_last\n",
    "output_df['HR_last']=HR_last\n",
    "\n",
    "end_df = pd.concat([output_df, dataframe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df.to_csv(\"Signal_pair.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
