{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,Input,BatchNormalization,MaxPooling1D,concatenate\n",
    "from keras.utils import np_utils,multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as bek\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data cell\n",
    "\"\"\"\n",
    "df1=pd.read_csv('/home/dp/Desktop/1_12_train_BG/pair_end_merge_BG_random_HR-train_12.csv',index_col=0)\n",
    "\n",
    "\n",
    "cond2 = df1['count']!=0\n",
    "df1 = df1[cond2]\n",
    "\n",
    "#normalize\n",
    "target = 'BG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(ref_values, pred_values):\n",
    "\n",
    "    #Checking to see if the lengths of the reference and prediction arrays are the same\n",
    "    assert (len(ref_values) == len(pred_values)), \"Unequal number of values (reference : {}) (prediction : {}).\".format(len(ref_values), len(pred_values))\n",
    "\n",
    "    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning\n",
    "    if max(ref_values) > 400 or max(pred_values) > 400:\n",
    "        print(\"Input Warning: the maximum reference value {} or the maximum prediction value {} exceeds the normal physiological range of glucose (<400 mg/dl).\".format(max(ref_values), max(pred_values)))\n",
    "    if min(ref_values) < 0 or min(pred_values) < 0:\n",
    "        print(\"Input Warning: the minimum reference value {} or the minimum prediction value {} is less than 0 mg/dl.\".format(min(ref_values),  min(pred_values)))\n",
    "\n",
    "    #Statistics from the data\n",
    "    zone = [0] * 5\n",
    "    for i in range(len(ref_values)):\n",
    "        if (ref_values[i] <= 70 and pred_values[i] <= 70) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):\n",
    "            zone[0] += 1    #Zone A\n",
    "\n",
    "        elif (ref_values[i] >= 180 and pred_values[i] <= 70) or (ref_values[i] <= 70 and pred_values[i] >= 180):\n",
    "            zone[4] += 1    #Zone E\n",
    "\n",
    "        elif ((ref_values[i] >= 70 and ref_values[i] <= 290) and pred_values[i] >= ref_values[i] + 110) or ((ref_values[i] >= 130 and ref_values[i] <= 180) and (pred_values[i] <= (7/5)*ref_values[i] - 182)):\n",
    "            zone[2] += 1    #Zone C\n",
    "        elif (ref_values[i] >= 240 and (pred_values[i] >= 70 and pred_values[i] <= 180)) or (ref_values[i] <= 175/3 and pred_values[i] <= 180 and pred_values[i] >= 70) or ((ref_values[i] >= 175/3 and ref_values[i] <= 70) and pred_values[i] >= (6/5)*ref_values[i]):\n",
    "            zone[3] += 1    #Zone D\n",
    "        else:\n",
    "            zone[1] += 1    #Zone B\n",
    "            \n",
    "    confidence_score = round((zone[0]*5+zone[1]*2.5)/(len(ref_values)*5)*100,2)\n",
    "    \n",
    "    return confidence_score,zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c1(ref_values, pred_values):\n",
    "    \n",
    "    sum_a = 0\n",
    "    for i in range(len(ref_values)):\n",
    "        d = abs(pred_values[i]-ref_values[i])\n",
    "        if((d/ref_values[i])<1):\n",
    "            a = abs(d/ref_values[i]-1)\n",
    "        else:\n",
    "            a = 0\n",
    "        sum_a = sum_a + a\n",
    "    acc = sum_a/len(ref_values)\n",
    "    acc = round(acc*100,2)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model cell\n",
    "'''\n",
    "def base_model():\n",
    "    in_s = Input((406, 2))\n",
    "    model_s = Convolution1D(nb_filter=256, filter_length=3) (in_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=256, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=512, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=1024, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Convolution1D(nb_filter=2048, filter_length=3) (model_s)\n",
    "    model_s = BatchNormalization(axis=-1)(model_s)\n",
    "    model_s = Activation('relu')(model_s)\n",
    "    model_s = MaxPooling1D(pool_size=2)(model_s)\n",
    "    \n",
    "    model_s = Flatten()(model_s)\n",
    "    \n",
    "    input1 = keras.layers.Input(shape=(1,))\n",
    "    c = keras.layers.Concatenate(axis=-1)([model_s, input1])\n",
    "    \n",
    "    m = BatchNormalization(axis=-1)(c)\n",
    "    m = Dense(4096,activation='relu')(m)\n",
    "    m = Dense(2048,activation='relu')(m)\n",
    "    out = Dense(1,activation='linear')(m)\n",
    "    \n",
    "    model = Model(inputs=[in_s,input1], outputs=[out])\n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999)\n",
    "    model = multi_gpu_model(model,gpus=6)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali_step(train_temp,vali_temp):\n",
    "    X_train_s = train_temp.iloc[:,7:413]\n",
    "    X_train_s_last = train_temp.iloc[:,414:820]\n",
    "    X_vali_s = vali_temp.iloc[:,7:413]\n",
    "    X_vali_s_last = vali_temp.iloc[:,414:820]\n",
    "    \n",
    "    f1=['BG']\n",
    "    Y_train = train_temp[f1]\n",
    "    Y_train = scalert.transform(Y_train)\n",
    "    \n",
    "    # reshape train data\n",
    "    X_train_r_s = np.zeros((len(X_train_s), 406, 2))\n",
    "    X_train_r_s[:, :, 0] = X_train_s\n",
    "    X_train_r_s[:, :, 1] = X_train_s_last\n",
    "\n",
    "    # reshape vali data\n",
    "    X_vali_r_s = np.zeros((len(X_vali_s), 406, 2))\n",
    "    X_vali_r_s[:, :, 0] = X_vali_s\n",
    "    X_vali_r_s[:, :, 1] = X_vali_s_last\n",
    "    \n",
    "    \n",
    "    f2=['BG_last']\n",
    "    # reshape train data\n",
    "    X_train_r_f = train_temp[f2]\n",
    "\n",
    "    # reshape vali data\n",
    "    X_vali_r_f = vali_temp[f2]\n",
    "    \n",
    "    \n",
    "    #fit\n",
    "    model= base_model()\n",
    "    model.fit([X_train_r_s,X_train_r_f], Y_train, epochs=1000, batch_size=3000,verbose=0)\n",
    "\n",
    "    \n",
    "    vali_pred = model.predict([X_vali_r_s,X_vali_r_f])\n",
    "    vali_pred1 = scalert.inverse_transform(vali_pred)\n",
    "    vali_temp['BG_p']=vali_pred1\n",
    "    temp_a=0\n",
    "    temp_b=0\n",
    "    vali_BG_r=[]\n",
    "    vali_BG_p=[]\n",
    "                        \n",
    "    for i,item in enumerate(vali_temp['Person No']):\n",
    "        if((vali_temp['Person No'].iloc[i]!=temp_a) | (vali_temp['time'].iloc[i]!=temp_b)):\n",
    "            \n",
    "            #administrator mode\n",
    "            vali_BG_r.append(vali_temp['BG'].iloc[i])\n",
    "            temp = vali_temp[(vali_temp['Person No']==vali_temp['Person No'].iloc[i])&(vali_temp['time']==vali_temp['time'].iloc[i])]\n",
    "            t = np.median(temp['BG_p'])\n",
    "            vali_BG_p.append(t)\n",
    "            temp_a = vali_temp['Person No'].iloc[i]\n",
    "            temp_b = vali_temp['time'].iloc[i]\n",
    "            \n",
    "    print(vali_BG_p)\n",
    "    print(vali_BG_r)\n",
    "    del model\n",
    "    bek.clear_session()\n",
    "    gc.collect()\n",
    "    return (vali_BG_p,vali_BG_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(train_temp,test_temp):\n",
    "    X_train_s = train_temp.iloc[:,7:413]\n",
    "    X_train_s_last = train_temp.iloc[:,414:820]\n",
    "    X_test_s = test_temp.iloc[:,7:413]\n",
    "    X_test_s_last = test_temp.iloc[:,414:820]\n",
    "    \n",
    "    f1=['BG']\n",
    "    Y_train = train_temp[f1]\n",
    "    Y_train = scalert.transform(Y_train)\n",
    "    \n",
    "    # reshape train data\n",
    "    X_train_r_s = np.zeros((len(X_train_s), 406, 2))\n",
    "    X_train_r_s[:, :, 0] = X_train_s\n",
    "    X_train_r_s[:, :, 1] = X_train_s_last\n",
    "\n",
    "    # reshape vali data\n",
    "    X_test_r_s = np.zeros((len(X_test_s), 406, 2))\n",
    "    X_test_r_s[:, :, 0] = X_test_s\n",
    "    X_test_r_s[:, :, 1] = X_test_s_last\n",
    "    \n",
    "    f2=['BG_last']\n",
    "    # reshape train data\n",
    "    X_train_r_f = train_temp[f2]\n",
    "\n",
    "    # reshape vali data\n",
    "    X_test_r_f = test_temp[f2]\n",
    "    \n",
    "    #fit\n",
    "    model= base_model()\n",
    "    model.fit([X_train_r_s,X_train_r_f], Y_train, epochs=1000, batch_size=3000,verbose=0)\n",
    "\n",
    "    \n",
    "    test_pred = model.predict([X_test_r_s,X_test_r_f])\n",
    "    test_pred1 = scalert.inverse_transform(test_pred)\n",
    "    test_temp['BG_p']=test_pred1\n",
    "    temp_a=0\n",
    "    temp_b=0\n",
    "    test_BG_r=[]\n",
    "    test_BG_p=[]\n",
    "                        \n",
    "    for i,item in enumerate(test_temp['Person No']):\n",
    "        if((test_temp['Person No'].iloc[i]!=temp_a) | (test_temp['time'].iloc[i]!=temp_b)):\n",
    "            \n",
    "            #administrator mode\n",
    "            test_BG_r.append(test_temp['BG'].iloc[i])\n",
    "            temp = test_temp[(test_temp['Person No']==test_temp['Person No'].iloc[i])&(test_temp['time']==test_temp['time'].iloc[i])]\n",
    "            t = np.median(temp['BG_p'])\n",
    "            test_BG_p.append(t)\n",
    "            temp_a = test_temp['Person No'].iloc[i]\n",
    "            temp_b = test_temp['time'].iloc[i]\n",
    "            \n",
    "    print(test_BG_p)\n",
    "    print(test_BG_r)\n",
    "    del model\n",
    "    bek.clear_session()\n",
    "    gc.collect()\n",
    "    return (test_BG_p,test_BG_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "testingNo = 1\n",
    "################\n",
    "\n",
    "\n",
    "test_p=[]\n",
    "test_r=[]\n",
    "vali_p=[]\n",
    "vali_r=[]\n",
    "vali_score=[]\n",
    "vali_zone=[]\n",
    "test_zone=[]\n",
    "acc=[]\n",
    "score_1=[]\n",
    "score_2=[]\n",
    "\n",
    "for test_time in range(13,16):\n",
    "    test  = df1[(df1['count']==testingNo)&(df1['count_time']==test_time)]\n",
    "    if(test.empty):\n",
    "        continue\n",
    "    else:\n",
    "        test_index = test.index\n",
    "        data_base = df1.drop(test_index)\n",
    "        t = data_base[target]\n",
    "        t = t.values.reshape(-1, 1)\n",
    "        scalert = preprocessing.MinMaxScaler().fit(t)\n",
    "        test_train = data_base[(data_base['count']==testingNo)&(data_base['count_time']<13)]\n",
    "    \n",
    "        for vali_time in range(2,13):\n",
    "            vali  = data_base[(data_base['count']==testingNo)&(data_base['count_time']==vali_time)]\n",
    "            if(vali.empty):\n",
    "                continue\n",
    "            else:\n",
    "                vali_index = vali.index\n",
    "                vali_train = data_base[(data_base['count']==testingNo)&(data_base['count_time']<13)]\n",
    "                vali_train = vali_train.drop(vali_index)\n",
    "                (temp_pred,temp_real) = vali_step(vali_train,vali)\n",
    "                print(\"test No:\",testingNo,\" test time:\",test_time,\" vali time:\",vali_time)\n",
    "                vali_p.append(temp_pred)\n",
    "                vali_r.append(temp_real)\n",
    "        \n",
    "        reshape_p=[]\n",
    "        reshape_r=[]\n",
    "\n",
    "        for i in range(len(vali_p)):\n",
    "            for j in range(len((vali_p[i]))):\n",
    "                reshape_p.append(vali_p[i][j])\n",
    "        for i in range(len(vali_r)):\n",
    "            for j in range(len((vali_r[i]))):\n",
    "                reshape_r.append(vali_r[i][j]) \n",
    "        vali_p=[]\n",
    "        vali_r=[]        \n",
    "        vali_conf,vali_z = c(reshape_r,reshape_p)\n",
    "        vali_score.append(vali_conf)\n",
    "        vali_zone.append(vali_z)\n",
    "        \n",
    "        p_1=[]\n",
    "        p_2=[]\n",
    "        for i in range(0,10):\n",
    "            (temp_pred,temp_real) = test_step(test_train,test)\n",
    "            p_1.append(temp_pred[0])\n",
    "            p_2.append(temp_pred[1])\n",
    "        p_1.remove(max(p_1))\n",
    "        p_1.remove(min(p_1))\n",
    "        p_2.remove(max(p_2))\n",
    "        p_2.remove(min(p_2))\n",
    "        s_1 = np.std(p_1)/np.median(p_1)\n",
    "        s_2 = np.std(p_2)/np.median(p_2)\n",
    "        score_1.append(s_1)\n",
    "        score_2.append(s_2)\n",
    "        \n",
    "        \n",
    "        m_pred=[np.median(p_1),np.median(p_2)]\n",
    "        \n",
    "        test_p.append(m_pred)\n",
    "        test_r.append(temp_real)\n",
    "        \n",
    "        reshape_p=[]\n",
    "        reshape_r=[]\n",
    "\n",
    "        for i in range(len(m_pred)):\n",
    "                reshape_p.append(m_pred[i])\n",
    "        for i in range(len(temp_real)):\n",
    "                reshape_r.append(temp_real[i])\n",
    "                \n",
    "        no_mind,test_z = c(reshape_r,reshape_p)\n",
    "        test_acc = c1(reshape_r,reshape_p)\n",
    "        \n",
    "        acc.append(test_acc)\n",
    "        test_zone.append(test_z)\n",
    "        \n",
    "        print(\"test No:\",testingNo,\"test time:\",test_time,\"confidence score:\",vali_conf,\"%\",'vali_zone:',vali_z)\n",
    "        print(\"BG real:\",temp_real,\" BG pred:\",m_pred,\"accuracy:\",test_acc,\"%\",'test_zone:',test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'confidence score':vali_score, 'vali_zone':vali_zone , 'BG_real': test_r, 'BG_pred': test_p, 'test_zone':test_zone,'score_1':score_1,'score_2':score_2,'accuracy':acc}\n",
    "df_f = pd.DataFrame(data = d)\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind =[]\n",
    "for j in range(13,len(df_f.index)+13):\n",
    "    ind.append(j)\n",
    "    \n",
    "df_f.index=ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#screen\n",
    "mark = []\n",
    "reason = []\n",
    "\n",
    "for i,item in enumerate(df_f['confidence score']):\n",
    "    print(i)\n",
    "    his_M = (max(set(df1[(df1['count']==testingNo)&(df1['count_time'] < df_f.index[i])]['BG'])))\n",
    "    his_m = (min(set(df1[(df1['count']==testingNo)&(df1['count_time'] < df_f.index[i])]['BG'])))\n",
    "    #print(his_M,his_m)\n",
    "    if((df_f.index[i]==4)|(df_f.index[i]==5)):\n",
    "        if(df_f['confidence score'].iloc[i] < 50):\n",
    "            print('test time :',df_f.index[i],' reason 1')\n",
    "            mark.append('reject')\n",
    "            reason.append(1)\n",
    "        else:\n",
    "            if( (df_f['score_1'].iloc[i]>0.07) | (df_f['score_2'].iloc[i] > 0.07) ):\n",
    "                print('test time :',df_f.index[i],' reason 2')\n",
    "                mark.append('reject')\n",
    "                reason.append(2)\n",
    "            else:\n",
    "                temp=[]\n",
    "                for j in range(len([float(item) for item in df_f['BG_pred'].iloc[i][1:-1].split(',')])):\n",
    "                    temp.append([float(item) for item in df_f.iloc[i]['BG_pred'][1:-1].split(',')][j])\n",
    "                thistime_M=max(temp)\n",
    "                thistime_m=min(temp)\n",
    "                if( (thistime_M > (his_M*1.1)) | ((thistime_m < (his_m*0.9)) )):\n",
    "                    print('test time :',df_f.index[i],' reason 3')\n",
    "                    mark.append('reject')\n",
    "                    reason.append(3)\n",
    "                else:\n",
    "                    if(thistime_m < 200):\n",
    "                        if(thistime_m*1.3 < thistime_M):\n",
    "                            print('test time :',df_f.index[i],' reason 4')\n",
    "                            mark.append('reject')\n",
    "                            reason.append(4)\n",
    "                        else:\n",
    "                            print('test time :',df_f.index[i],' pass')\n",
    "                            mark.append('pass')\n",
    "                            reason.append(0)\n",
    "                    else:\n",
    "                        if(thistime_m*1.35 < thistime_M):\n",
    "                            print('test time :',df_f.index[i],' reason 4')\n",
    "                            mark.append('reject')\n",
    "                            reason.append(4)\n",
    "                        else:\n",
    "                            print('test time :',df_f.index[i],' pass')\n",
    "                            mark.append('pass')\n",
    "                            reason.append(0)\n",
    "    else:\n",
    "        if(df_f['confidence score'].iloc[i] < 60):\n",
    "            print('test time :',df_f.index[i],' reason 1')\n",
    "            mark.append('reject')\n",
    "            reason.append(1)\n",
    "        else:\n",
    "            if( (df_f['score_1'].iloc[i]>0.07) | (df_f['score_2'].iloc[i] > 0.07) ):\n",
    "                print('test time :',df_f.index[i],' reason 2')\n",
    "                mark.append('reject')\n",
    "                reason.append(2)\n",
    "            else:\n",
    "                temp=[]\n",
    "                for j in range(len([float(item) for item in df_f['BG_pred'].iloc[i][1:-1].split(',')])):\n",
    "                    temp.append([float(item) for item in df_f.iloc[i]['BG_pred'][1:-1].split(',')][j])\n",
    "                thistime_M=max(temp)\n",
    "                thistime_m=min(temp)\n",
    "                if( (thistime_M > (his_M*1.1)) | ((thistime_m < (his_m*0.9)) )):\n",
    "                    print('test time :',df_f.index[i],' reason 3')\n",
    "                    mark.append('reject')\n",
    "                    reason.append(3)\n",
    "                else:\n",
    "                    if(thistime_m < 200):\n",
    "                        if(thistime_m*1.3 < thistime_M):\n",
    "                            print('test time :',df_f.index[i],' reason 4')\n",
    "                            mark.append('reject')\n",
    "                            reason.append(4)\n",
    "                        else:\n",
    "                            print('test time :',df_f.index[i],' pass')\n",
    "                            mark.append('pass')\n",
    "                            reason.append(0)\n",
    "                    else:\n",
    "                        if(thistime_m*1.35 < thistime_M):\n",
    "                            print('test time :',df_f.index[i],' reason 4')\n",
    "                            mark.append('reject')\n",
    "                            reason.append(4)\n",
    "                        else:\n",
    "                            print('test time :',df_f.index[i],' pass')\n",
    "                            mark.append('pass')\n",
    "                            reason.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['mark']=mark\n",
    "df_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
